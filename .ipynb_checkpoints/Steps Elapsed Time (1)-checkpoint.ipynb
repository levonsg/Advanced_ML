{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps Elapsed Time\n",
    "This notebook calculates a number of KPI metrics and a summary of status for test results given the user-specified query and grouping parameters. It ties into the **Test Monitor Service** for retrieving filtered test results, the **Notebook Execution Service** for running outside of Jupyterhub, and **Grafana Dashboards** for displaying results.\n",
    "\n",
    "The parameters and output use a schema recognized by the NI Plotly Graph Plugin for Grafana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import Python modules for executing the notebook. Pandas is used for building and handling dataframes. Scrapbook is used for recording data for the Notebook Execution Service. The SystemLink Test Monitor Client provides access to test result data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "from dateutil import tz\n",
    "import re\n",
    "\n",
    "import systemlink.clients.nitestmonitor as testmon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "- `results_filter`: Dynamic Linq query filter for test results from the Test Monitor Service\n",
    "  - Options: Any valid Test Monitor Results Dynamic Linq filter\n",
    "  - Default: `'startedWithin <= \"30.0:0:0\"'`\n",
    "- `products_filter`: Dynamic Linq query filter for test results based on products from the Test Monitor Service\n",
    "  - Options: Any valid Test Monitor Products Dynamic Linq filter\n",
    "  - Default: `''`\n",
    " - `step_name_filter`: Filters results from Steps API results based on reults from the Test Monitor Service\n",
    "  - Default: `''`\n",
    "- `group_by`: The dimension along which to reduce; what each bar in the output graph represents  \n",
    "  - Options: Day, System, Test Program, Operator, Part Number  \n",
    "  - Default: `'Day'`\n",
    "\n",
    "Parameters are also listed in the metadata for the parameters cell, along with their default values. The Notebook Execution services uses that metadata to pass parameters from the Test Monitor Reports page to this notebook. Available `group_by` options are listed in the metadata as well; the Test Monitor Reports page uses these to validate inputs sent to the notebook.\n",
    "\n",
    "To see the metadata, select the code cell and click the wrench icon in the far left panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "parameters": {
      "group_by": "Day",
      "products_filter": "",
      "results_filter": "startedWithin <= \"30.0:0:0\"",
      "steps_filter": ""
     }
    },
    "systemlink": {
     "namespaces": [
      "ni-testmanagement"
     ],
     "outputs": [
      {
       "display_name": "Unique Steps",
       "id": "us_df",
       "type": "data_frame"
      },
      {
       "display_name": "Steps Elapsed Time",
       "id": "set_df",
       "type": "data_frame"
      }
     ],
     "parameters": [
      {
       "display_name": "Steps",
       "id": "step_name_filter",
       "type": "string"
      },
      {
       "default_display": {
        "products_filter": [],
        "results_filter": [
         {
          "queryOperandUnit": "DAYS",
          "queryOperandValue": 30,
          "queryOperator": "LESS_THAN_OR_EQUAL",
          "queryOperatorName": "startedWithin"
         }
        ]
       },
       "display_name": "Query by",
       "id": "results_filter",
       "type": "test_monitor_result_query"
      }
     ],
     "version": 2
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "results_filter = 'startedWithin <= \"180.0:0:0\"'\n",
    "step_name_filter = ''\n",
    "products_filter = ''\n",
    "group_by = 'Day'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping from grouping options to Test Monitor terminology\n",
    "Translate the grouping options shown in the Test Monitor Reports page to keywords recognized by the Test Monitor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not currently implemented\n",
    "groups_map = {\n",
    "    'Day': 'started_at',\n",
    "    'System': 'system_id',\n",
    "    'Test Program': 'program_name',\n",
    "    'Operator': 'operator',\n",
    "    'Part Number': 'part_number',\n",
    "    'Workspace': 'workspace'\n",
    "}\n",
    "grouping = groups_map[group_by]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Filter\n",
    "Clean up filters from Grafana to API format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts Grafana filter {,} into or statements for API filter\n",
    "def format_result_filter(string_filter):\n",
    "    str_pat = r'(([a-zA-Z]+) = \"{(.*?)}\")\\s?'\n",
    "    pattern = re.compile(str_pat, re.IGNORECASE)\n",
    "    match = pattern.findall(string_filter)\n",
    "    \n",
    "    if match:\n",
    "        # Return format [(whole group, field_name, field_value), ...]\n",
    "        for group in match:\n",
    "            orig_string_group = group[0]\n",
    "            name = '\" || ' + group[1] + ' = \"'\n",
    "            value = group[2].split(',')\n",
    "            new_string_group = '(' + group[1] + ' = \"' + name.join(value)  + '\")'\n",
    "            string_filter = string_filter.replace(orig_string_group, new_string_group)\n",
    "    else:\n",
    "        print(\"No matches\")\n",
    "        \n",
    "    return string_filter\n",
    "    \n",
    "results_filter = format_result_filter(results_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format step name filter\n",
    "\n",
    "def format_step_filter(string_filter):\n",
    "    steps_filter = ''\n",
    "    if string_filter != \"\":\n",
    "        if \",\" in string_filter:\n",
    "            step_filter_list = string_filter[1:-1].split(\",\")\n",
    "\n",
    "            for step in step_filter_list:\n",
    "                if steps_filter != '':\n",
    "                    steps_filter += ' || '\n",
    "\n",
    "                steps_filter += 'name == \"' + step + '\"'\n",
    "        else:\n",
    "            steps_filter = 'name == \"{}\"'.format(string_filter)\n",
    "            \n",
    "        steps_filter = '(' + steps_filter + ')'\n",
    "        \n",
    "        return steps_filter\n",
    "            \n",
    "    return string_filter\n",
    "        \n",
    "step_name_filter = format_step_filter(step_name_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Monitor client\n",
    "Establish a connection to SystemLink over HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = testmon.ApiClient()\n",
    "results_api = testmon.ResultsApi(api_client)\n",
    "steps_api = testmon.StepsApi(api_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for results\n",
    "Query the Test Monitor Service for results matching the `results_filter` and `steps_filter` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def perform_batched_query(query_function, query, response_field):\n",
    "    results = []\n",
    "\n",
    "    response = await query_function(post_body=query)\n",
    "    while response.continuation_token:\n",
    "        results = results + getattr(response, response_field)\n",
    "        query.continuation_token = response.continuation_token\n",
    "        response = await query_function(post_body=query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_projection_filter = ['ID', 'STATUS', 'STARTED_AT', 'UPDATED_AT', 'PROGRAM_NAME', 'SYSTEM_ID', 'HOST_NAME', 'SERIAL_NUMBER', 'TOTAL_TIME_IN_SECONDS']\n",
    "results_query = testmon.ResultsAdvancedQuery(\n",
    "    results_filter, product_filter=products_filter, projection=results_projection_filter, order_by=testmon.ResultField.STARTED_AT, take=5000\n",
    ")\n",
    "\n",
    "results = await perform_batched_query(results_api.query_results_v2, results_query, 'results')\n",
    "results_list = [result.to_dict() for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "steps_filter = 'totalTimeInSeconds > 0 && name != \"Wait\"  && stepType != \"Wait\" && parentId != \"root\"'\n",
    "steps_projection_filter = ['NAME', 'STEP_TYPE', 'STEP_ID', 'RESULT_ID', 'STATUS', 'TOTAL_TIME_IN_SECONDS', 'STARTED_AT']\n",
    "\n",
    "if step_name_filter != '':\n",
    "    steps_filter = steps_filter + ' && ' + step_name_filter\n",
    "\n",
    "if results:\n",
    "    steps_query = testmon.StepsAdvancedQuery(filter=steps_filter, result_filter=results_filter, projection=steps_projection_filter, order_by=testmon.StepField.STARTED_AT, take=5000)\n",
    "    steps = await perform_batched_query(steps_api.query_steps_v2, steps_query, 'steps')\n",
    "\n",
    "steps_list = [step.to_dict() for step in steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get group names\n",
    "Collect the group name for each result based on the `group_by` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = []\n",
    "for result in results_list:\n",
    "    if grouping in result:\n",
    "        group_names.append(result[grouping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pandas dataframe\n",
    "Put the data into a dataframe whose columns are id, serial number, program_name, start time, and group name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_results = {\n",
    "    'id': [result['id'] for result in results_list],\n",
    "    'serial_number': [result['serial_number'] for result in results_list],\n",
    "    'program_name': [result['program_name'] for result in results_list],\n",
    "    'status': [result['status']['status_type'] for result in results_list],\n",
    "    'started_at': [result['started_at'] for result in results_list],\n",
    "    'system_id': [result['system_id'] for result in results_list],\n",
    "    'host_name': [result['host_name'] for result in results_list],\n",
    "    'total_time_in_seconds': [result['total_time_in_seconds'] for result in results_list], #elapsed time\n",
    "    grouping: group_names\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_steps = {\n",
    "    'result_id': [step['result_id'] for step in steps_list],\n",
    "    'status': [step['status']['status_type'] if step['status'] else None for step in steps_list],\n",
    "    'step_name': [step['name'] for step in steps_list],\n",
    "    'step_id': [step['step_id'] for step in steps_list],\n",
    "    'step_type': [step['step_type'] for step in steps_list],\n",
    "    'started_at': [step['started_at'] for step in steps_list],\n",
    "    'step_total_time_in_seconds': [step['total_time_in_seconds'] for step in steps_list] #elapsed time\n",
    "}\n",
    "\n",
    "df_steps = pd.DataFrame.from_dict(formatted_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by and Pivot Data\n",
    "Group data by host_name and program_name and pivot from row to columnar format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with results table to get host name\n",
    "df_steps = pd.merge(df_steps, df_results[['id', 'program_name', 'host_name', 'total_time_in_seconds']], how='inner', left_on=\"result_id\", right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify table and add new fields\n",
    "temp_df_steps = df_steps[['result_id', 'started_at', 'status', 'host_name', 'step_total_time_in_seconds', 'step_name']].copy()\n",
    "temp_df_steps['host_program'] = temp_df_steps['host_name'].fillna('N/A') + '_' + temp_df_steps['step_name'].fillna('N/A')\n",
    "temp_df_steps['local_time'] = temp_df_steps['started_at'].apply(lambda x: x.astimezone(tz.tzlocal()).replace(tzinfo=None))\n",
    "\n",
    "temp_df_steps = temp_df_steps[['result_id', 'local_time', 'status', 'step_total_time_in_seconds', 'host_program']]\n",
    "\n",
    "#temp_df_steps\n",
    "\n",
    "# Group by and pivot table\n",
    "df_steps_pv = pd.pivot_table(temp_df_steps, values='step_total_time_in_seconds', index=['local_time', 'result_id'], columns=['host_program'])\n",
    "df_steps_pv.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "#df_steps_pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If dataframe is empty, return df with 1 row with current datetime\n",
    "curr_time = datetime.datetime.now().astimezone(tz.tzlocal()).replace(tzinfo=None)\n",
    "\n",
    "if df_steps_pv.empty:\n",
    "    df_steps_pv = pd.DataFrame(data = curr_time, columns = ['local_time'], index = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle grouping by day\n",
    "If the grouping is by day, the group name is the date and time when the test started in UTC. To group all test results from a single day together, convert to server time and remove time information from the group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_by_day(df, grouping_list):\n",
    "    df_results_unique = df.groupby(grouping_list).first().reset_index()\n",
    "    df_results_copy = copy.copy(df_results_unique)\n",
    "    df_results_copy.fillna(value='', inplace=True)\n",
    "\n",
    "    if grouping == 'started_at':\n",
    "        truncated_times = []\n",
    "        for val in df_results_copy[grouping]:\n",
    "            local_time = val.astimezone(tz.tzlocal())\n",
    "            truncated_times.append(str(datetime.date(local_time.year, local_time.month, local_time.day)))\n",
    "        df_results_copy[grouping] = truncated_times\n",
    "    return df_results_copy\n",
    "    \n",
    "df_steps_copy = grouping_by_day(df_steps, ['result_id', 'step_id']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate and Pivot\n",
    "Get average elapsed time and pivot by host_testprogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps_elasped_time = df_steps_copy.groupby([grouping, 'step_name', 'program_name', 'host_name']).agg({'step_total_time_in_seconds': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps_elasped_time['host_program'] = df_steps_elasped_time['host_name'].fillna('N/A') + '_' + df_steps_elasped_time['step_name'].fillna('N/A')\n",
    "\n",
    "df_steps_elasped_time_pv = pd.pivot_table(df_steps_elasped_time, values='step_total_time_in_seconds', index=['started_at'], columns=['host_program'])\n",
    "\n",
    "df_steps_elasped_time_pv.fillna(0, inplace=True)\n",
    "df_steps_elasped_time_pv.reset_index(inplace=True)\n",
    "\n",
    "#df_steps_elasped_time_pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results into groups\n",
    "Aggregate the data for each unique group and status.\n",
    "\n",
    "*See documentation for [size](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.size.html) and [unstack](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html) here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If filters are empty, return empty string    \n",
    "def is_df_empty(df, add_val):\n",
    "    if df.empty:\n",
    "        df.loc[0] = [add_val]\n",
    "    return df\n",
    "\n",
    "# Create lists for filters\n",
    "unique_steps = is_df_empty(pd.DataFrame(data=df_steps['step_name'].unique(), columns=['step_name']), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataframe to the SystemLink reports output format\n",
    "The result format for a SystemLink report consists of a list of output objects as defined below:\n",
    "- `type`: The type of the output. Accepted values are 'data_frame' and 'scalar'.\n",
    "- `id`: Corresponds to the id specified in the 'output' metadata. Used for returning multiple outputs with the 'V2' report format.\n",
    "- `data`: A dict representing the 'data_frame' type output data.\n",
    "    - `columns`: A list of dicts containing the names and data type for each column in the dataframe.\n",
    "    - `values`: A list of lists containing the dataframe values. The sublists are ordered according to the 'columns' configuration.\n",
    "- `value`: The value returned for the 'scalar' output type.\n",
    "- `config`: The configurations for the given output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dict(df):\n",
    "    df_dict = {\n",
    "        'columns': pd.io.json.build_table_schema(df, index=False)['fields'],\n",
    "        'values': df.values.tolist(),\n",
    "    }\n",
    "    return df_dict\n",
    "\n",
    "unique_steps_dict = {\n",
    "    'type': 'data_frame',\n",
    "    'id': 'us_df',\n",
    "    'data': df_dict(unique_steps)\n",
    "}\n",
    "\n",
    "steps_elasped_time_dict = {\n",
    "    'type': 'data_frame',\n",
    "    'id': 'set_df',\n",
    "    'data': df_dict(df_steps_pv) #df_steps_elasped_time_pv\n",
    "}\n",
    "\n",
    "\n",
    "result = [unique_steps_dict, steps_elasped_time_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record results with Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue('result', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
